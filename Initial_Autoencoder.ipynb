{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28",
      "mount_file_id": "1XWxBQCNlbtG_zSf646D-cHpwWaenYhOK",
      "authorship_tag": "ABX9TyOyYl80bf160YgVXFZU8bhM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbelKosh/Jane-Street-Challenge/blob/main/Initial_Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0F76U4pcKw2a"
      },
      "outputs": [],
      "source": [
        "import os, gc\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOMEWQYtDnZg",
        "outputId": "585195b0-186c-490b-c98d-30842d2019f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "miwQxTXpN2rV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimze for memory\n",
        "\n",
        "def reduce_mem_usage(self, float16_as32=True):\n",
        "    start_mem = df.memory_usage().sum() / 1024**2  # Calculate intial memory\n",
        "    print(f'Memory usage of dataframe is {start_mem:.2f} MB')\n",
        "\n",
        "    for col in df.columns: # Itterate through each column\n",
        "        col_type = df[col].dtype\n",
        "        if col_type != object and str(col_type)!='category': # Accepts only numerical types\n",
        "            c_min,c_max = df[col].min(),df[col].max()\n",
        "            if str(col_type)[:3] == 'int': # For int type variable\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8) # If the range is between -128 to 127, convert to int8\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16) # Between -32,768 to 32,767, convert to int16\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32) # Between -2,147,483,648 to 2,147,483,647, convert to int32\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  # Between -9,223,372,036,854,775,808 to 9,223,372,036,854,775,807, convert to int64\n",
        "            else: # For floating point type\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    if float16_as32: # If the data needs higher accuracy, choose float32\n",
        "                        df[col] = df[col].astype(np.float32)\n",
        "                    else:\n",
        "                        df[col] = df[col].astype(np.float16)\n",
        "                # If the value is within the value range of float32, convert\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                # If the value is within the value range of float64, convert\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "\n",
        "    # Calculate the memory after the end\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    # Calculate the percentage by which memory has been reduced\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "BBfEM35VPZTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "# Step 1: Load and Prepare Data\n",
        "###############################################################################\n",
        "\n",
        "# Define the path to the input data directory\n",
        "# If the local directory exists, use it; otherwise, use the Kaggle input directory\n",
        "input_path =  '/content/drive/MyDrive/Jane Street Challenge'\n",
        "\n",
        "# Create a directory to store the trained models\n",
        "os.system('mkdir models')\n",
        "\n",
        "# Flag to determine if the script is in training mode or not\n",
        "TRAINING = True\n",
        "\n",
        "# Define the feature names based on the number of features (79 in this case)\n",
        "feature_names = [f\"feature_{i:02d}\" for i in range(79)]\n",
        "target_col = \"responder_6\"\n",
        "\n",
        "# Number of dates to skip from the beginning of the dataset\n",
        "skip_dates = 500\n",
        "\n",
        "# Number of validation dates to use\n",
        "num_valid_dates = 100\n",
        "\n",
        "# If in training mode, load the training data\n",
        "if TRAINING:\n",
        "    # Load the training data from a Parquet file\n",
        "    df = pd.read_parquet(f'{input_path}/train.parquet')\n",
        "\n",
        "    # Forward Fill values\n",
        "    df[feature_names] = df[feature_names].ffill().fillna(0)\n",
        "\n",
        "    # Reduce memory usage of the DataFrame (function not provided here)\n",
        "    df = reduce_mem_usage(df, False)\n",
        "\n",
        "    # Filter the DataFrame to include only dates greater than or equal to skip_dates\n",
        "    df = df[df['date_id'] >= skip_dates].reset_index(drop=True)\n",
        "\n",
        "    # Get unique dates from the DataFrame\n",
        "    dates = df['date_id'].unique()\n",
        "\n",
        "    # Define validation dates as the last `num_valid_dates` dates\n",
        "    valid_dates = dates[-num_valid_dates:]\n",
        "\n",
        "    # Define training dates as all dates except the last `num_valid_dates` dates\n",
        "    train_dates = dates[:-num_valid_dates]\n",
        "\n",
        "    # Display the last few rows of the DataFrame (for debugging purposes)\n",
        "    print(df.tail())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9MsGVU2P4v0",
        "outputId": "786df2c7-22e5-4c1c-8737-afba57f4ca50",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory usage of dataframe is 15910.22 MB\n",
            "Memory usage after optimization is: 8179.83 MB\n",
            "Decreased by 48.6%\n",
            "          date_id  time_id  symbol_id    weight  feature_00  feature_01  \\\n",
            "39577176     1698      967         34  3.242188    2.525391   -0.722168   \n",
            "39577177     1698      967         35  1.079102    1.857422   -0.790527   \n",
            "39577178     1698      967         36  1.033203    2.515625   -0.672363   \n",
            "39577179     1698      967         37  1.243164    2.664062   -0.889160   \n",
            "39577180     1698      967         38  3.193359    2.728516   -0.745117   \n",
            "\n",
            "          feature_02  feature_03  feature_04  feature_05  ...  responder_0  \\\n",
            "39577176    2.544922    2.478516    0.417480    0.785645  ...     0.243530   \n",
            "39577177    2.746094    2.339844    0.845215    0.651367  ...     0.850098   \n",
            "39577178    2.289062    2.521484    0.255127    0.919922  ...     0.395752   \n",
            "39577179    2.312500    3.101562    0.324463    0.619141  ...     1.925781   \n",
            "39577180    2.789062    2.343750    0.454834    0.862793  ...     1.228516   \n",
            "\n",
            "          responder_1  responder_2  responder_3  responder_4  responder_5  \\\n",
            "39577176     0.166870     0.385010    -0.174316    -0.066040    -0.038757   \n",
            "39577177     0.909180     1.015625     0.235962     0.122559     0.099548   \n",
            "39577178    -0.292480    -3.216797    -0.535156    -0.178467    -1.808594   \n",
            "39577179     0.479492     3.621094    -0.107117    -0.063599     1.205078   \n",
            "39577180     0.512695    -0.050873     0.160889     0.080750    -0.078247   \n",
            "\n",
            "          responder_6  responder_7  responder_8  partition_id  \n",
            "39577176    -0.132324    -0.022430    -0.252441             9  \n",
            "39577177    -0.249634    -0.123596    -0.460693             9  \n",
            "39577178    -0.065369    -0.000367    -0.125122             9  \n",
            "39577179    -0.148682    -0.026581    -0.256348             9  \n",
            "39577180    -0.138550    -0.038757    -0.211914             9  \n",
            "\n",
            "[5 rows x 93 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set values\n",
        "\n",
        "X = df[feature_names].values\n",
        "y = df['responder_6'].values\n",
        "days = df['date_id'].values\n",
        "weights = df['weight'].values"
      ],
      "metadata": {
        "id": "-YCRYWQ_ZM9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#try with f_32/f_64\n",
        "#weights = weights / np.sum(weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zQiY3QLO4ec",
        "outputId": "b9847bc8-5b1d-4bfa-945f-c0268e5133d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-6dd58f0c87a0>:1: RuntimeWarning: invalid value encountered in divide\n",
            "  weights = weights / np.sum(weights)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights /= weights.max()"
      ],
      "metadata": {
        "id": "nVhAc1afOHvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.config import threading\n",
        "\n",
        "# Configure TensorFlow to use all CPU cores\n",
        "threading.set_intra_op_parallelism_threads(8)  # 0 lets TensorFlow decide\n",
        "\n",
        "\n",
        "# Verify the configuration\n",
        "print(f\"Inter-op threads: {threading.get_inter_op_parallelism_threads()}\")\n",
        "\n",
        "'''\n",
        "# 1. Detect TPU\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU:', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "    print('TPU not found. Using CPU/GPU.')\n",
        "\n",
        "# 2. Initialize TPU\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "print(\"Number of replicas:\", strategy.num_replicas_in_sync)\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "Q721YiD6KYJ-",
        "outputId": "5f6cf772-c4b5-4579-e765-1c141fb2ae44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inter-op threads: 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# 1. Detect TPU\\ntry:\\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\\n    print(\\'Running on TPU:\\', tpu.master())\\nexcept ValueError:\\n    tpu = None\\n    print(\\'TPU not found. Using CPU/GPU.\\')\\n\\n# 2. Initialize TPU\\nif tpu:\\n    tf.config.experimental_connect_to_cluster(tpu)\\n    tf.tpu.experimental.initialize_tpu_system(tpu)\\n    strategy = tf.distribute.TPUStrategy(tpu)\\nelse:\\n    strategy = tf.distribute.get_strategy() \\n\\nprint(\"Number of replicas:\", strategy.num_replicas_in_sync)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid = df[feature_names].loc[df['date_id'].isin(valid_dates)].values\n",
        "X_train = df[feature_names].loc[df['date_id'].isin(train_dates)].values"
      ],
      "metadata": {
        "id": "QKCsVFFoX3n4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "# Define architecture\n",
        "\n",
        "input_dim = X.shape[1]\n",
        "\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "encoder_layer = Dense(32, activation='relu')(input_layer) # Hidden\n",
        "encoder_layer = Dense(16, activation='relu')(encoder_layer) # Hidden\n",
        "\n",
        "encoder_layer = Dense(4, activation='relu')(encoder_layer) # Bottleneck\n",
        "\n",
        "decoder_layer = Dense(16, activation='relu')(encoder_layer) # Hidden\n",
        "decoder_layer = Dense(32, activation='relu')(decoder_layer) # Hidden\n",
        "\n",
        "output_layer = Dense(input_dim, activation='linear')(decoder_layer) # Reconstruct Output\n",
        "\n",
        "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')"
      ],
      "metadata": {
        "id": "L1n_Yq2eL2tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.fit(\n",
        "    X_train, X_train,\n",
        "    epochs=50,\n",
        "    batch_size=8192,\n",
        "    validation_data=[X_valid, X_valid]\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-k41ZZZN1Og",
        "outputId": "ea7d5f76-e14c-4d0e-95f6-a9fd7067ec24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "4378/4378 [==============================] - 30s 6ms/step - loss: 0.7617 - val_loss: 0.6755\n",
            "Epoch 2/50\n",
            "4378/4378 [==============================] - 29s 7ms/step - loss: 0.7614 - val_loss: 0.6808\n",
            "Epoch 3/50\n",
            "4378/4378 [==============================] - 27s 6ms/step - loss: 0.7609 - val_loss: 0.6803\n",
            "Epoch 4/50\n",
            "4378/4378 [==============================] - 28s 6ms/step - loss: 0.7603 - val_loss: 0.6847\n",
            "Epoch 5/50\n",
            "4378/4378 [==============================] - 28s 6ms/step - loss: 0.7596 - val_loss: 0.6821\n",
            "Epoch 6/50\n",
            "4378/4378 [==============================] - 27s 6ms/step - loss: 0.7589 - val_loss: 0.6703\n",
            "Epoch 7/50\n",
            "4378/4378 [==============================] - 29s 7ms/step - loss: 0.7565 - val_loss: 0.6754\n",
            "Epoch 8/50\n",
            "4378/4378 [==============================] - 28s 7ms/step - loss: 0.7546 - val_loss: 0.6735\n",
            "Epoch 9/50\n",
            "4378/4378 [==============================] - 27s 6ms/step - loss: 0.7542 - val_loss: 0.6704\n",
            "Epoch 10/50\n",
            "4378/4378 [==============================] - 29s 7ms/step - loss: 0.7537 - val_loss: 0.6709\n",
            "Epoch 11/50\n",
            "4378/4378 [==============================] - 27s 6ms/step - loss: 0.7533 - val_loss: 0.6685\n",
            "Epoch 12/50\n",
            "4378/4378 [==============================] - 29s 7ms/step - loss: 0.7531 - val_loss: 0.6655\n",
            "Epoch 13/50\n",
            "4378/4378 [==============================] - 29s 7ms/step - loss: 0.7527 - val_loss: 0.6697\n",
            "Epoch 14/50\n",
            "4378/4378 [==============================] - 29s 7ms/step - loss: 0.7525 - val_loss: 0.6666\n",
            "Epoch 15/50\n",
            "4378/4378 [==============================] - 28s 6ms/step - loss: 0.7523 - val_loss: 0.6718\n",
            "Epoch 16/50\n",
            "4378/4378 [==============================] - 29s 7ms/step - loss: 0.7521 - val_loss: 0.6678\n",
            "Epoch 17/50\n",
            "4378/4378 [==============================] - 28s 6ms/step - loss: 0.7518 - val_loss: 0.6624\n",
            "Epoch 18/50\n",
            "4378/4378 [==============================] - 28s 6ms/step - loss: 0.7516 - val_loss: 0.6704\n",
            "Epoch 19/50\n",
            "4378/4378 [==============================] - 28s 6ms/step - loss: 0.7515 - val_loss: 0.6638\n",
            "Epoch 20/50\n",
            "4378/4378 [==============================] - 29s 7ms/step - loss: 0.7514 - val_loss: 0.6668\n",
            "Epoch 21/50\n",
            "4378/4378 [==============================] - 29s 7ms/step - loss: 0.7511 - val_loss: 0.6681\n",
            "Epoch 22/50\n",
            "4378/4378 [==============================] - 28s 6ms/step - loss: 0.7509 - val_loss: 0.6612\n",
            "Epoch 23/50\n",
            "4378/4378 [==============================] - 28s 6ms/step - loss: 0.7508 - val_loss: 0.6658\n",
            "Epoch 24/50\n",
            "4378/4378 [==============================] - 28s 6ms/step - loss: 0.7506 - val_loss: 0.6680\n",
            "Epoch 25/50\n",
            "4378/4378 [==============================] - 28s 6ms/step - loss: 0.7505 - val_loss: 0.6606\n",
            "Epoch 26/50\n",
            "4378/4378 [==============================] - 28s 6ms/step - loss: 0.7504 - val_loss: 0.6646\n",
            "Epoch 27/50\n",
            "4378/4378 [==============================] - 28s 6ms/step - loss: 0.7502 - val_loss: 0.6638\n",
            "Epoch 28/50\n",
            "4378/4378 [==============================] - 30s 7ms/step - loss: 0.7502 - val_loss: 0.6642\n",
            "Epoch 29/50\n",
            "4378/4378 [==============================] - 29s 7ms/step - loss: 0.7500 - val_loss: 0.6601\n",
            "Epoch 30/50\n",
            "4378/4378 [==============================] - 29s 7ms/step - loss: 0.7497 - val_loss: 0.6582\n",
            "Epoch 31/50\n",
            "4378/4378 [==============================] - 29s 7ms/step - loss: 0.7496 - val_loss: 0.6588\n",
            "Epoch 32/50\n",
            "4378/4378 [==============================] - 29s 7ms/step - loss: 0.7495 - val_loss: 0.6617\n",
            "Epoch 33/50\n",
            "4378/4378 [==============================] - 28s 6ms/step - loss: 0.7493 - val_loss: 0.6646\n",
            "Epoch 34/50\n",
            "4378/4378 [==============================] - 29s 7ms/step - loss: 0.7491 - val_loss: 0.6685\n",
            "Epoch 35/50\n",
            "4378/4378 [==============================] - 29s 7ms/step - loss: 0.7485 - val_loss: 0.6566\n",
            "Epoch 36/50\n",
            "4378/4378 [==============================] - 28s 6ms/step - loss: 0.7481 - val_loss: 0.6613\n",
            "Epoch 37/50\n",
            "4378/4378 [==============================] - 27s 6ms/step - loss: 0.7476 - val_loss: 0.6569\n",
            "Epoch 38/50\n",
            "4378/4378 [==============================] - 30s 7ms/step - loss: 0.7471 - val_loss: 0.6592\n",
            "Epoch 39/50\n",
            "4378/4378 [==============================] - 29s 7ms/step - loss: 0.7465 - val_loss: 0.6591\n",
            "Epoch 40/50\n",
            "4378/4378 [==============================] - 30s 7ms/step - loss: 0.7459 - val_loss: 0.6627\n",
            "Epoch 41/50\n",
            "4378/4378 [==============================] - 30s 7ms/step - loss: 0.7454 - val_loss: 0.6592\n",
            "Epoch 42/50\n",
            "4378/4378 [==============================] - 29s 7ms/step - loss: 0.7448 - val_loss: 0.6632\n",
            "Epoch 43/50\n",
            "4378/4378 [==============================] - 28s 6ms/step - loss: 0.7446 - val_loss: 0.6662\n",
            "Epoch 44/50\n",
            "4378/4378 [==============================] - 28s 6ms/step - loss: 0.7438 - val_loss: 0.6620\n",
            "Epoch 45/50\n",
            "4378/4378 [==============================] - 29s 7ms/step - loss: 0.7433 - val_loss: 0.6577\n",
            "Epoch 46/50\n",
            "4378/4378 [==============================] - 27s 6ms/step - loss: 0.7425 - val_loss: 0.6539\n",
            "Epoch 47/50\n",
            "4378/4378 [==============================] - 27s 6ms/step - loss: 0.7419 - val_loss: 0.6555\n",
            "Epoch 48/50\n",
            "4378/4378 [==============================] - 27s 6ms/step - loss: 0.7413 - val_loss: 0.6554\n",
            "Epoch 49/50\n",
            "4378/4378 [==============================] - 28s 6ms/step - loss: 0.7406 - val_loss: 0.6591\n",
            "Epoch 50/50\n",
            "4378/4378 [==============================] - 29s 7ms/step - loss: 0.7400 - val_loss: 0.6585\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c5b78173c70>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reconstruct the input\n",
        "X_reconstructed = autoencoder.predict(X)\n",
        "\n",
        "# Compute reconstruction error\n",
        "reconstruction_error = np.mean(np.square(X - X_reconstructed), axis=1)\n",
        "print(\"Reconstruction Error (first 10 samples):\", reconstruction_error[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2NE1rBXQLVA",
        "outputId": "e81bc4a8-0979-4075-e440-9b213a470e42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1236787/1236787 [==============================] - 1505s 1ms/step\n",
            "Reconstruction Error (first 10 samples): [1.0698845 1.2499732 1.3263661 1.1549952 1.5845288 1.0523058 0.8955766\n",
            " 1.2136109 1.1093584 2.0604274]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reconstruct the input\n",
        "X_reconstruct = autoencoder.predict(X_valid)\n",
        "\n",
        "# Compute reconstruction error\n",
        "reconstruction_error = np.mean(np.square(X_valid - X_reconstruct), axis=1)\n",
        "print(\"Reconstruction Error (first 10 samples):\", reconstruction_error[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuFzejxXek8o",
        "outputId": "0c1d4fd0-99a0-4f40-e74f-73fe788c32d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116130/116130 [==============================] - 141s 1ms/step\n",
            "Reconstruction Error (first 10 samples): [1.0294298 1.3772562 1.1812094 0.9509004 1.2838373 1.359329  2.2602086\n",
            " 1.0162623 1.0174031 1.7014194]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the encoder model\n",
        "encoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer(index=2).output)  # Assuming the bottleneck is layer 2\n",
        "\n",
        "# Get latent representations\n",
        "latent_representations = encoder.predict(X)\n",
        "print(\"Latent Representations (first 5 samples):\")\n",
        "print(latent_representations[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77v9KZseWJyT",
        "outputId": "d0201b86-31b3-48c5-e61f-9d09a49d762c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1236787/1236787 [==============================] - 1410s 1ms/step\n",
            "Latent Representations (first 5 samples):\n",
            "[[ 7.4739966   0.          0.          7.1995497   5.4352612  32.019962\n",
            "   0.          7.883161    1.1627146   4.2156353   0.          4.0005655\n",
            "   6.112464   15.459115    1.6614232   0.        ]\n",
            " [ 0.          8.884517   12.341624   17.718355    0.         31.952633\n",
            "   0.         51.99388    14.388683    7.340246    0.         18.85402\n",
            "  10.702978    0.         15.232538    4.894465  ]\n",
            " [ 2.440923    0.          0.          4.1892395   2.2123868   5.1951084\n",
            "   0.          3.0551047   2.0659585   3.0791738   0.          3.9523578\n",
            "   1.3333149   7.36479     0.          0.        ]\n",
            " [ 6.693313    0.          0.         18.836302    2.10054    64.50085\n",
            "   0.          0.3724654   0.6031202  10.317776    0.          1.6614748\n",
            "   4.7767944  13.1036825   0.          0.        ]\n",
            " [ 7.7207236   0.          0.          7.7659307   5.916567   26.937994\n",
            "   0.          2.6678982   0.77926576  9.121556    0.          7.0814943\n",
            "   8.430646   15.732739    1.735568    0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set threshold (e.g., mean + 2*std of reconstruction error)\n",
        "threshold = np.mean(reconstruction_error) + 2 * np.std(reconstruction_error)\n",
        "\n",
        "# Identify anomalies\n",
        "anomalies = np.where(reconstruction_error > threshold)[0]\n",
        "print(\"Anomalous Samples Indices:\", anomalies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCSNnKxoWgH9",
        "outputId": "abb640dd-c611-4573-c1fd-98e5317040c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anomalous Samples Indices: [  36845   54437   54496 ... 3709163 3711486 3711854]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "# Flatten for metric computation\n",
        "X_flat = X.reshape(-1, X.shape[-1])\n",
        "X_reconstructed_flat = X_reconstructed.reshape(-1, X.shape[-1])\n",
        "\n",
        "# MAE and R^2\n",
        "mae = mean_absolute_error(X_flat, X_reconstructed_flat)\n",
        "r2 = r2_score(X_flat, X_reconstructed_flat)\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"R^2 Score: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foRl7JuxWjpD",
        "outputId": "2d24045e-1ba2-4c77-c32f-7ac9a7d5f4f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 0.5047721862792969\n",
            "R^2 Score: 0.334540992975235\n"
          ]
        }
      ]
    }
  ]
}